{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-22T13:46:08.320713Z",
     "start_time": "2023-10-22T13:46:08.318972Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "#Ollama\n",
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Set the API key when using OpenAI embeddings\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:07.764179Z",
     "start_time": "2023-10-22T14:10:07.760696Z"
    }
   },
   "id": "19aa4507398334c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the  embeddings and the model\n",
    "For this notebook i will use the Mistral 7B model and the Ollama embeddings."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d516b0ea1eef2caa"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# Ollama embeddings\n",
    "embeddings_open = OllamaEmbeddings(model=\"mistral\")\n",
    "# OpenAI embeddings\n",
    "#embedding = OpenAIEmbeddings()\n",
    "\n",
    "llm_open = Ollama(  model=\"mistral\",\n",
    "                    #model='Llama2',\n",
    "                    callback_manager = CallbackManager([StreamingStdOutCallbackHandler()]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:13:11.219Z",
     "start_time": "2023-10-22T14:13:11.211783Z"
    }
   },
   "id": "31f873210b0f2bb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data \n",
    "Load the data from the directory and split it into chunks. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b004ca4c4196e842"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "41"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# Print number of txt files in directory\n",
    "loader = DirectoryLoader('/Users/erictak/PycharmProjects/freya/data/langchain_doc_small', glob=\"./*.txt\")\n",
    "\n",
    "# load pdfs from directory and print number of pdfs\n",
    "#loader = PyPDFLoader('/Users/erictak/PycharmProjects/Mistral7B/data/PDFs/How_to_build_your_carreer_in_AI.pdf')\n",
    "\n",
    "# load another file directly\n",
    "#loader = DirectoryLoader('/your/path/to/file.txt')\n",
    "\n",
    "doc = loader.load ( )\n",
    "len(doc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:13.263732Z",
     "start_time": "2023-10-22T14:10:11.537487Z"
    }
   },
   "id": "381e27a6499e6d71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Print the first document"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "172ffbcf0eae8b99"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Aleph Alpha\\n\\nAleph Alpha# The Luminous series is a family of large language models. This example goes over how to use LangChain to interact with Aleph Alpha models\\n\\n# Install the package\\n\\n!pip install aleph\\n\\n\\n\\nalpha\\n\\n\\n\\nclient\\n\\n# create a new token: https://docs.aleph-alpha.com/docs/account/#create-a-new-token\\n\\nfrom getpass import getpass\\n\\nALEPH_ALPHA_API_KEY = getpass()\\n\\nfrom langchain.llms import AlephAlpha from langchain import PromptTemplate, LLMChain\\n\\ntemplate = \"\"\"Q: {question}\\n\\nA:\"\"\"\\n\\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\\n\\nllm = AlephAlpha(model=\"luminous\\n\\n\\n\\nextended\", maximum_tokens=20, stop_sequences=[\"Q:\"], aleph_alpha_api_key=ALEPH_ALPHA_API_KEY)\\n\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n\\nquestion = \"What is AI?\"\\n\\nllm_chain.run(question)\\n\\n\\' Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems.\\\\n\\'\\n\\nprevious\\n\\nAI21\\n\\nnext\\n\\nAnyscale\\n\\nBy Harrison Chase\\n\\nÂ© Copyright 2023, Harrison Chase.\\n\\nLast updated on Jun 13, 2023.' metadata={'source': '/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/20_Aleph_Alpha_Aleph.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(doc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:13.265066Z",
     "start_time": "2023-10-22T14:10:13.263071Z"
    }
   },
   "id": "dc0aad101a41700c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the text into chunks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df1a5e0be0624637"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Splitting the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter (chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(doc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:13.613910Z",
     "start_time": "2023-10-22T14:10:13.608962Z"
    }
   },
   "id": "b7fac36b7b5690f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Count the number of chunks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6921794ad8962108"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "378"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:14.484937Z",
     "start_time": "2023-10-22T14:10:14.480689Z"
    }
   },
   "id": "a40c8b5d391da327"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Print the first chunk"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d10b6fb845bc037"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(page_content='Aleph Alpha\\n\\nAleph Alpha# The Luminous series is a family of large language models. This example goes over how to use LangChain to interact with Aleph Alpha models\\n\\n# Install the package\\n\\n!pip install aleph\\n\\n\\n\\nalpha\\n\\n\\n\\nclient\\n\\n# create a new token: https://docs.aleph-alpha.com/docs/account/#create-a-new-token\\n\\nfrom getpass import getpass\\n\\nALEPH_ALPHA_API_KEY = getpass()\\n\\nfrom langchain.llms import AlephAlpha from langchain import PromptTemplate, LLMChain\\n\\ntemplate = \"\"\"Q: {question}\\n\\nA:\"\"\"', metadata={'source': '/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/20_Aleph_Alpha_Aleph.txt'})"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:15.422234Z",
     "start_time": "2023-10-22T14:10:15.417849Z"
    }
   },
   "id": "6ed4c59383cdf49c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embed and store the texts\n",
    "Supplying a persist_directory will store the embeddings on disk, so that they can be loaded later."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce407d89f1110a05"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "#persist_directory = 'PDFs_How_to_build_your_carreer_in_AI'\n",
    "\n",
    "# Langchain documentation\n",
    "persist_directory = 'vdb_langchain_doc_small'\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts,\n",
    "                                 \n",
    "                                 # Chose the embedding you want to use\n",
    "                                 # embedding=embeddings_open,\n",
    "                                 embedding=embeddings_open,\n",
    "                                 \n",
    "                                 persist_directory=persist_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:20.077716Z",
     "start_time": "2023-10-22T14:10:17.208717Z"
    }
   },
   "id": "d0caf622e36bc7c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save to disc\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe0b87a8f3b1ab1a"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Persist the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:21.985550Z",
     "start_time": "2023-10-22T14:10:21.980419Z"
    }
   },
   "id": "3b1d92ce6d0af525"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choose persistence directory and load from disk"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a369c7fa73f32fe6"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Langchain documentation\n",
    "persist_directory = 'vdb_langchain_doc_small'\n",
    "\n",
    "# PDFs from directory\n",
    "#persist_directory = 'PDFs_How_to_build_your_carreer_in_AI'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:34.951964Z",
     "start_time": "2023-10-22T14:10:34.948316Z"
    }
   },
   "id": "21727fbc2cef3b6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da269fc5e9808fc4"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embeddings_open\n",
    "                  #embedding_function=embeddings_open\n",
    "                  )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:37.062806Z",
     "start_time": "2023-10-22T14:10:37.050960Z"
    }
   },
   "id": "f012c910a6504b8b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the retriever"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e77acb94af62830"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:38.243239Z",
     "start_time": "2023-10-22T14:10:38.233437Z"
    }
   },
   "id": "dcc8e33565f576dc"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"What is this document about?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:39.857550Z",
     "start_time": "2023-10-22T14:10:39.467642Z"
    }
   },
   "id": "ccd5f8b671622d9a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Print the number of documents that are returned"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31727f127da2e2f1"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs\n",
    "len(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:40.542775Z",
     "start_time": "2023-10-22T14:10:40.537340Z"
    }
   },
   "id": "d5b5b15ffee9a9a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cite sources"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e8652ea0c04d52e"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:41.439707Z",
     "start_time": "2023-10-22T14:10:41.435163Z"
    }
   },
   "id": "22f6c67728e4116"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the chain to answer questions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8745711b022aca6f"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=llm_open,\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True,\n",
    "                                  verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:42.349496Z",
     "start_time": "2023-10-22T14:10:42.345521Z"
    }
   },
   "id": "3ff137a6d5dc18a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50c26eb8f42b29e1"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "This document appears to be a Quickstart Guide for getting started with a software product or service. It contains sections on Getting Started, Modules, Use Cases, Reference Docs, and Ecosystem, as well as Additional Resources.\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "This document appears to be a Quickstart Guide for getting started with a software product or service. It contains sections on Getting Started, Modules, Use Cases, Reference Docs, and Ecosystem, as well as Additional Resources.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/2_Quickstart_Guide_Contents.txt\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/8_Getting_Started_Getting.txt\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/7_LLMs_LLMs_Note.txt\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/0_Welcome_to_LangChain.txt\n"
     ]
    }
   ],
   "source": [
    "# Question\n",
    "query = \"What is this document about?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:51.532368Z",
     "start_time": "2023-10-22T14:10:43.252111Z"
    }
   },
   "id": "a93117b6c901b0fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a prompt template to use in the chain "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0b86c74c46570ef"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def build_prompt(template_num=\"template_1\"):\n",
    "    template = \"\"\" You are a helpful chatbot, named RSLT. You answer the questions of the customers giving a lot of details based on what you find in the context.\n",
    "Do not say anything that is not in the website\n",
    "You are to act as though you're having a conversation with a human.\n",
    "You are only able to answer questions, guide and assist, and provide recommendations to users. You cannot perform any other tasks outside of this.\n",
    "Your tone should be professional and friendly.\n",
    "Your purpose is to answer questions people might have, however if the question is unethical you can choose not to answer it.\n",
    "Your responses should always be one paragraph long or less.\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "\n",
    "    template2 = \"\"\"You are a helpful chatbot, named RSLT. You answer the questions of the customers giving a lot of details based on what you find in the context. \n",
    "    Your responses should always be one paragraph long or less.\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "\n",
    "    if template_num == \"template_1\":\n",
    "        prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=template)\n",
    "        return prompt\n",
    "\n",
    "    elif template_num == \"template_2\":\n",
    "        prompt = PromptTemplate(input_variables=[\"question\"], template=template2)\n",
    "        return prompt\n",
    "\n",
    "    else:\n",
    "        print(\"Please choose a valid template\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:10:58.421712Z",
     "start_time": "2023-10-22T14:10:58.417481Z"
    }
   },
   "id": "75cee000aa10d601"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the chain to answer questions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf9408c72c79e80a"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=llm_open,\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True,\n",
    "                                  verbose=True,\n",
    "                                  chain_type_kwargs={\"prompt\": build_prompt(\"template_1\")})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:11:00.705541Z",
     "start_time": "2023-10-22T14:11:00.701934Z"
    }
   },
   "id": "84d64a45a91aa4c"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "This document appears to be a guide for users who want to quickly get started with a specific software or system. The guide is divided into several sections, including Getting Started, Modules, Use Cases, Reference Docs, Ecosystem, and Additional Resources. It seems that the guide provides an overview of the features and functionalities of the software, as well as some practical examples of how to use it in different contexts. The author of the guide is Harrison Chase, and it was last updated on June 14, 2023.\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "This document appears to be a guide for users who want to quickly get started with a specific software or system. The guide is divided into several sections, including Getting Started, Modules, Use Cases, Reference Docs, Ecosystem, and Additional Resources. It seems that the guide provides an overview of the features and functionalities of the software, as well as some practical examples of how to use it in different contexts. The author of the guide is Harrison Chase, and it was last updated on June 14, 2023.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/2_Quickstart_Guide_Contents.txt\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/8_Getting_Started_Getting.txt\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/7_LLMs_LLMs_Note.txt\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/0_Welcome_to_LangChain.txt\n"
     ]
    }
   ],
   "source": [
    "# Question\n",
    "query = \"What is this document about?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:11:06.994282Z",
     "start_time": "2023-10-22T14:11:01.264850Z"
    }
   },
   "id": "844c66124849bc0f"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "LangChain is a framework for developing applications powered by language models. It enables developers to build data-aware and agentic applications that can call out to a language model, connect it to other sources of data, and allow it to interact with its environment. LangChain includes a variety of modules, use cases, reference documents, an ecosystem, and additional resources to support the development of these applications.\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "LangChain is a framework for developing applications powered by language models. It enables developers to build data-aware and agentic applications that can call out to a language model, connect it to other sources of data, and allow it to interact with its environment. LangChain includes a variety of modules, use cases, reference documents, an ecosystem, and additional resources to support the development of these applications.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/0_Welcome_to_LangChain.txt\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/1_Welcome_to_LangChain.txt\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/1_Welcome_to_LangChain.txt\n",
      "/Users/erictak/PycharmProjects/freya/data/langchain_doc_small/0_Welcome_to_LangChain.txt\n"
     ]
    }
   ],
   "source": [
    "# Question\n",
    "query = \"What is Lanchain?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T14:11:16.561630Z",
     "start_time": "2023-10-22T14:11:11.121119Z"
    }
   },
   "id": "63197e0cca2ae5eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5cd522fb30e2c4d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
